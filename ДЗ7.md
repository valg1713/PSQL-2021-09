Инстанс instance-6, кластер main, база buffer_templ  
Погнали!

Выставил значения

    checkpoint_timeout = 30s
	max_wal_size = 16GB
	min_wal_size = 4GB
	checkpoint_completion_target = 0.9

до запуска pgbench, размер wal файлов - 234 МБ

запустили pgbench, на 10 минут, чтобы посмотреть. Через минуту - убили постгрес. Размер wal файлов не изменился. Это связано с тем, что количество транзакций уместилось в этот или меньший размер.
В логах постгреса появилась отметка об восстановлении из wal файла.

	User@instance-6:~$ sudo tail /var/log/postgresql/postgresql-13-main.log
    2021-11-13 09:03:41.615 UTC [22533] LOG:  database system was not properly shut down; automatic recovery in progress
    2021-11-13 09:03:41.619 UTC [22533] LOG:  redo starts at 0/E5F90BE8
    2021-11-13 09:03:41.900 UTC [22533] LOG:  invalid record length at 0/E722ABE0: wanted 24, got 0
    2021-11-13 09:03:41.900 UTC [22533] LOG:  redo done at 0/E722ABB8
    2021-11-13 09:03:42.144 UTC [22532] LOG:  database system is ready to accept connections



Запускаем pgbench еще раз, так же на 10 минут. Размер не изменился, причина - та же. Нужно что-то по массивнее и посложнее.
 
Смотрим статистику чекпоинтов. До запуска pgbench - 112 чекпоинтов.

	checkpoints_timed | checkpoints_req | checkpoint_write_time | checkpoint_sync_time |
	------------------+-----------------+-----------------------+----------------------
	              133 |               0 |                383251 |                 6275 |


за время работы pgbench сработал 21 чекпоинт. Все были выполнены вовремя, но... Время обработки и записи на диск (write_time) стало аж 38 секунд против 30 секунд для 1 чекпоинта. Учитывая, что checkpoint_completion_target = 0.9, а sync_time - 6,2 секунды, надо делать чекпоинты реже, чтобы не было наложения выполнения 1 чекпоинта на другой.

Иначе - смысл этого? Получится, что с такой базой произойдет "бдыщь", а у нас не то чтобы 2 минимально необходимых чекпоинта не прошло, а вообще... Консистентное состояние было в момент последней корректной остановки.  Плюс, создание чекпоинта - ресурсоемкое заниятие, т.к. надо записать на диск все страницы памяти.

Поэтому чекпоинты должны быть настроены таким образом, чтобы между окончанием записи на диск предыдущего чекпоинта и началом записи следующего чекпоинта был разрыв по времени. Какой - выявляется опытным путем исходя из конкретной БД и железа.  Для контроля чекпоинтов необходимо использовать механизмы checkpoint_warning и checkpoint_timeout.


Сравнение tps в синхронном/асинхронном режиме.
В асинхронном режиме tps подскочил почти в 2 раза, с уверенных 570-600 до стабильных 1200-1250 на протяжении первых 130 секунд теста. Потом снизился до 640, что все равно выше, чем  520-570 при синхронной фиксации транзакций.

Это объясняется тем, что в асинхронном режим фиксации транзакций сервер не ждет подтверждения о записи данных о транзакции в WAL и на диск. В асинхронном режиме в WAL сервер сообщает о логическом завершении транзакции и не ждет, пока транзакция будет записана, на диск пишутся целые страницы.

Контроль контрольной суммы.
Создаем кластер

	$sudo pg_createcluster 13 sync -p 5433 --start -d /var/lib/postgresql/13/sync -- --data-checksums
	**оверквотинг скинпнут**
	Ver Cluster Port Status Owner    Data directory              Log file
	13  sync    5433 online postgres /var/lib/postgresql/13/sync /var/log/postgresql/postgresql-13-sync.log
	$sudo -u postgres psql -p 5433

Проверяем, что контрольные суммы включены
	postgres=# show data_checksums;
	data_checksums
	----------------
				on
			(1 row)

создаем и заполняем таблицу:

	=#create database test;
	=#\c test
	=#CREATE TABLE test(i int); INSERT INTO test SELECT s.id FROM generate_series(1,10) AS s(id); select * from test limit 3;

	
	 i
	----
	   1
	   2
	   3
	(3 rows)
	\q

Узнаем, в каких файлах лежат данные таблицы:
	test=# SELECT pg_relation_filepath('test');
	pg_relation_filepath
	----------------------
	base/16384/16385

Останавливаем и портим данные в таблице

	test=# select * from test;
	WARNING:  page verification failed, calculated checksum 41051 but expected 48271
	ERROR:  invalid page in block 0 of relation base/16384/16385


После корябания данных (зашел в файл, и, варварски удалил пару символов в произвольных местах), при попытке выбрать данные, предсказуемо получил следующее:

	test=# select * from test;
	WARNING:  page verification failed, calculated checksum 41051 but expected 48271
	ERROR:  invalid page in block 0 of relation base/16384/16385

А теперь попробуем все таки прочитать данные:

	test=# set ignore_checksum_failure on;
	ERROR:  syntax error at or near "on"
	LINE 1: set ignore_checksum_failure on;
	                                    ^
	test=# set ignore_checksum_failure= on;select * from test;
	SET
	WARNING:  page verification failed, calculated checksum 41051 but expected 48271
	 i
	---
	
	
	(2 rows)



Выводы:  
1. Иметь бэкап.  
2. Иметь бэкап в другом месте, а не там где лежит база.  
3. Иметь бэкап в облаке.  
4. Машина, на которой крутится база, должна быть либо в отказоустойчивом облаке по HA Tier 3, либо в в гиперконвергентной среде, с фоновым снятием бэкапов.  
5. При повреждении данных и включенной проверке контрольных сумм, данные, конечно можно собрать, но лучше не портить себе время и нервы, а сразу откатываться на бэкап.
6. При невключенной проверке контрольных сумм - пересобрать кластер на включенную проверку. На всякий пожарный.  
7. Кстати, вот [тут](https://ardentperf.com/2019/11/08/postgresql-invalid-page-and-checksum-verification-failed/) неплохая статья по реагированию на развалившуюся базу с ошибкой контрольных сумм. Причем не только техническая, но и в плане бизнеса. Возьму на вооружение на работе.